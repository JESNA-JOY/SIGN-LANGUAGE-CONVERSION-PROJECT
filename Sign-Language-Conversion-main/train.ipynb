{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from gloss_dataset import GlossDataset\n",
    "from gloss_model import GlossModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data for training\n",
    "gd = GlossDataset()\n",
    "input_size = gd[0][0].shape[1]\n",
    "class_no = len(gd.classes)\n",
    "input_size, class_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide input and class size\n",
    "model = GlossModel(input_size, class_no)\n",
    "device = model.device\n",
    "model.to(device)\n",
    "optim = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sumamry writer\n",
    "writer=SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing and training dataLoader from single dataset using random_split\n",
    "# and also set training epoch\n",
    "split_ratio = 0.8\n",
    "batch_size = 1\n",
    "train_size = int(split_ratio*len(gd))\n",
    "test_size = len(gd)-train_size\n",
    "train_data, test_data = random_split(gd, [train_size, test_size])\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size,\n",
    "                      shuffle=True, pin_memory=False)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size,\n",
    "                     shuffle=True, pin_memory=False)\n",
    "epoch = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 1.6121\n",
      "Epoch 11/1000, Loss: 1.6007\n",
      "Epoch 21/1000, Loss: 1.5894\n",
      "Epoch 31/1000, Loss: 1.5690\n",
      "Epoch 41/1000, Loss: 1.5503\n",
      "Epoch 51/1000, Loss: 1.5226\n",
      "Epoch 61/1000, Loss: 1.4932\n",
      "Epoch 71/1000, Loss: 1.4697\n",
      "Epoch 81/1000, Loss: 1.4501\n",
      "Epoch 91/1000, Loss: 1.4293\n",
      "Epoch 101/1000, Loss: 1.4136\n",
      "Epoch 111/1000, Loss: 1.3951\n",
      "Epoch 121/1000, Loss: 1.3811\n",
      "Epoch 131/1000, Loss: 1.3622\n",
      "Epoch 141/1000, Loss: 1.3562\n",
      "Epoch 151/1000, Loss: 1.3397\n",
      "Epoch 161/1000, Loss: 1.3165\n",
      "Epoch 171/1000, Loss: 1.3100\n",
      "Epoch 181/1000, Loss: 1.3391\n",
      "Epoch 191/1000, Loss: 1.2897\n",
      "Epoch 201/1000, Loss: 1.2904\n",
      "Epoch 211/1000, Loss: 1.2789\n",
      "Epoch 221/1000, Loss: 1.2751\n",
      "Epoch 231/1000, Loss: 1.3021\n",
      "Epoch 241/1000, Loss: 1.2896\n",
      "Epoch 251/1000, Loss: 1.2565\n",
      "Epoch 261/1000, Loss: 1.2566\n",
      "Epoch 271/1000, Loss: 1.2528\n",
      "Epoch 281/1000, Loss: 1.2474\n",
      "Epoch 291/1000, Loss: 1.2367\n",
      "Epoch 301/1000, Loss: 1.2024\n",
      "Epoch 311/1000, Loss: 1.2019\n",
      "Epoch 321/1000, Loss: 1.1764\n",
      "Epoch 331/1000, Loss: 1.1700\n",
      "Epoch 341/1000, Loss: 1.1326\n",
      "Epoch 351/1000, Loss: 1.1411\n",
      "Epoch 361/1000, Loss: 1.1846\n",
      "Epoch 371/1000, Loss: 1.1508\n",
      "Epoch 381/1000, Loss: 1.1018\n",
      "Epoch 391/1000, Loss: 1.0619\n",
      "Epoch 401/1000, Loss: 1.0517\n",
      "Epoch 411/1000, Loss: 1.0613\n",
      "Epoch 421/1000, Loss: 1.0252\n",
      "Epoch 431/1000, Loss: 1.0334\n",
      "Epoch 441/1000, Loss: 1.1171\n",
      "Epoch 451/1000, Loss: 1.0015\n",
      "Epoch 461/1000, Loss: 0.9724\n",
      "Epoch 471/1000, Loss: 0.9628\n",
      "Epoch 481/1000, Loss: 0.9553\n",
      "Epoch 491/1000, Loss: 0.9489\n",
      "Epoch 501/1000, Loss: 0.9434\n",
      "Epoch 511/1000, Loss: 0.9384\n",
      "Epoch 521/1000, Loss: 1.1680\n",
      "Epoch 531/1000, Loss: 0.9748\n",
      "Epoch 541/1000, Loss: 0.9612\n",
      "Epoch 551/1000, Loss: 0.9759\n",
      "Epoch 561/1000, Loss: 0.9856\n",
      "Epoch 571/1000, Loss: 0.9430\n",
      "Epoch 581/1000, Loss: 0.9406\n",
      "Epoch 591/1000, Loss: 0.9395\n",
      "Epoch 601/1000, Loss: 0.9373\n",
      "Epoch 611/1000, Loss: 0.9359\n",
      "Epoch 621/1000, Loss: 1.1680\n",
      "Epoch 631/1000, Loss: 0.9648\n",
      "Epoch 641/1000, Loss: 0.9505\n",
      "Epoch 651/1000, Loss: 0.9478\n",
      "Epoch 661/1000, Loss: 0.9349\n",
      "Epoch 671/1000, Loss: 0.9342\n",
      "Epoch 681/1000, Loss: 0.9336\n",
      "Epoch 691/1000, Loss: 0.9330\n",
      "Epoch 701/1000, Loss: 1.3195\n",
      "Epoch 711/1000, Loss: 1.0630\n",
      "Epoch 721/1000, Loss: 0.9913\n",
      "Epoch 731/1000, Loss: 0.9504\n",
      "Epoch 741/1000, Loss: 1.1179\n",
      "Epoch 751/1000, Loss: 0.9650\n",
      "Epoch 761/1000, Loss: 0.9421\n",
      "Epoch 771/1000, Loss: 0.9236\n",
      "Epoch 781/1000, Loss: 0.9214\n",
      "Epoch 791/1000, Loss: 0.9205\n",
      "Epoch 801/1000, Loss: 0.9200\n",
      "Epoch 811/1000, Loss: 0.9197\n",
      "Epoch 821/1000, Loss: 1.1008\n",
      "Epoch 831/1000, Loss: 0.9437\n",
      "Epoch 841/1000, Loss: 0.9443\n",
      "Epoch 851/1000, Loss: 0.9941\n",
      "Epoch 861/1000, Loss: 0.9440\n",
      "Epoch 871/1000, Loss: 0.9434\n",
      "Epoch 881/1000, Loss: 0.9433\n",
      "Epoch 891/1000, Loss: 0.9431\n",
      "Epoch 901/1000, Loss: 0.9431\n",
      "Epoch 911/1000, Loss: 1.0423\n",
      "Epoch 921/1000, Loss: 0.9588\n",
      "Epoch 931/1000, Loss: 0.9328\n",
      "Epoch 941/1000, Loss: 0.9284\n",
      "Epoch 951/1000, Loss: 0.9554\n",
      "Epoch 961/1000, Loss: 0.9311\n",
      "Epoch 971/1000, Loss: 0.9308\n",
      "Epoch 981/1000, Loss: 0.9869\n",
      "Epoch 991/1000, Loss: 0.9310\n"
     ]
    }
   ],
   "source": [
    "# Start model training\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "    total_loss=0\n",
    "    for x_train, y_train in train_dl:\n",
    "        xtrain, y_train = x_train.to(device), y_train.to(device)\n",
    "        out = model(x_train)\n",
    "        loss = loss_fn(out, y_train.argmax(dim=1))\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dl)\n",
    "    writer.add_scalar(\"Loss/epoch\", avg_loss, i)\n",
    "\n",
    "    if (i % 10 == 0):\n",
    "        print(f\"Epoch {i+1}/{epoch}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc 0.7000\n",
      "Test Loss : 1.2209\n",
      "\n",
      "Total test samples :  20\n",
      "Correct predictions :  14\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Test set\n",
    "model.eval()\n",
    "tot_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_dl:\n",
    "        out = model(x_test)\n",
    "        y_test=y_test.argmax(dim=1)\n",
    "        loss = loss_fn(out, y_test)\n",
    "        tot_loss += loss.item()\n",
    "        y_pred = torch.argmax(out, dim=1)\n",
    "        correct += torch.sum(torch.eq(y_pred, y_test)).item()\n",
    "        total += y_test.shape[0]\n",
    "\n",
    "acc = correct / total\n",
    "loss = tot_loss / len(test_dl)\n",
    "print(f\"Test Acc {acc:.4f}\\nTest Loss : {loss:.4f}\\n\")\n",
    "print(\"Total test samples : \", total)\n",
    "print(\"Correct predictions : \", correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model, \"asl_recog_lstm.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swaram-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
